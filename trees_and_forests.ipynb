{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Comparison Assignment\n",
        "\n",
        "In this notebook, you will:\n",
        "1. **Load and preprocess** one of the provided datasets (e.g., `breast-cancer-wisconsin.data`).\n",
        "2. **Split** the data into training and testing sets.\n",
        "3. **Train** and **evaluate**:\n",
        "   - A **Decision Tree** (for classification) side-by-side with a **Logistic Regression** model.\n",
        "4. **Compare** their performance using metrics such as accuracy, classification report, and ROC AUC.\n",
        "5. **Extend** your analysis by building a **Random Forest** classifier on the same data and comparing its results to the previous models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Preprocess Data\n",
        "\n",
        "Load the **Breast Cancer Wisconsin** dataset. Handle missing values and encode the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column names from the UCI repository\n",
        "columns = [\n",
        "    'ID', 'ClumpThickness', 'UniformityCellSize', 'UniformityCellShape',\n",
        "    'MarginalAdhesion', 'SingleEpithelialCellSize', 'BareNuclei',\n",
        "    'BlandChromatin', 'NormalNucleoli', 'Mitoses', 'Class'\n",
        "]\n",
        "# Read the data, treating '?' as missing\n",
        "df = pd.read_csv('breast-cancer-wisconsin.data', names=columns, na_values='?')\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "# Features and target\n",
        "X = df.drop(['ID', 'Class'], axis=1)\n",
        "# Map Class: 2 -> benign (0), 4 -> malignant (1)\n",
        "y = df['Class'].map({2: 0, 4: 1})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train-Test Split\n",
        "\n",
        "Split the data into training and test sets (e.g., 70% train, 30% test)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Decision Tree vs. Logistic Regression\n",
        "\n",
        "Train both a Decision Tree classifier and a Logistic Regression model, then compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "# Train\n",
        "dt.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Probabilities for ROC AUC\n",
        "y_prob_dt = dt.predict_proba(X_test)[:, 1]\n",
        "y_prob_lr = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate\n",
        "for name, y_pred, y_prob in [\n",
        "    ('Decision Tree', y_pred_dt, y_prob_dt),\n",
        "    ('Logistic Regression', y_pred_lr, y_prob_lr)\n",
        "]:\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(\"Accuracy:\\t\", accuracy_score(y_test, y_pred))\n",
        "    print(\"ROC AUC:\\t\", roc_auc_score(y_test, y_prob))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discussion\n",
        "\n",
        "- Which model achieved higher accuracy? Higher AUC?\n",
        "- Examine the confusion matrices: where do the models make more mistakes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Random Forest Classifier\n",
        "\n",
        "Build a Random Forest on the same data and compare its performance with the Decision Tree and Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Train\n",
        "rf.fit(X_train, y_train)\n",
        "# Predict\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
        "# Evaluate\n",
        "print(\"=== Random Forest ===\")\n",
        "print(\"Accuracy:\\t\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"ROC AUC:\\t\", roc_auc_score(y_test, y_prob_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Comparison\n",
        "\n",
        "- Summarize performance of all three models.\n",
        "- Discuss trade-offs between interpretability (Decision Tree), simplicity (Logistic Regression), and ensemble power (Random Forest).\n",
        "\n",
        "---\n",
        "\n",
        "**Extension:**\n",
        "- Try tuning hyperparameters for the Decision Tree and Random Forest.\n",
        "- Apply the same workflow to another dataset (e.g., `heart-disease.data` or `adult.data`).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}